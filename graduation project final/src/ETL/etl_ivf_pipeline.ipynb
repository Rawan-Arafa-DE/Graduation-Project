{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de3414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL COMPLETED SUCCESSFULLY. Check warehouse DB and log file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "#  CONFIG\n",
    "# ==============================\n",
    "BASE_PATH = r\"E:\\work\\DEPI\\graduation promax\"\n",
    "\n",
    "RAW_DB = fr\"{BASE_PATH}\\data\\raw\\ivf_database_updated.db\"\n",
    "STAR_DB = fr\"{BASE_PATH}\\data\\warehouse\\ivf_star_schema.db\"\n",
    "SCHEMA_SQL = fr\"{BASE_PATH}\\src\\etl\\create_star_schema.sql\"\n",
    "LOG_FILE = fr\"{BASE_PATH}\\src\\etl\\logs\\etl_log_ivf.txt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(STAR_DB), exist_ok=True)\n",
    "\n",
    "# ==============================\n",
    "#  LOGGING\n",
    "# ==============================\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "logging.info(\"===== ETL STARTED =====\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  UTILS\n",
    "# ==============================\n",
    "def run_schema_sql():\n",
    "    \"\"\"\n",
    "    FULL REFRESH Ù„Ù„Ù€ star schema:\n",
    "    - Drop Ù„ÙƒÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„\n",
    "    - Create Ù…Ù† Ù…Ù„Ù create_star_schema.sql\n",
    "    \"\"\"\n",
    "    logging.info(\"Creating star schema from SQL file...\")\n",
    "    conn = sqlite3.connect(STAR_DB)\n",
    "    with open(SCHEMA_SQL, \"r\", encoding=\"utf-8\") as f:\n",
    "        sql_script = f.read()\n",
    "    conn.executescript(sql_script)\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    logging.info(\"Star schema created successfully.\")\n",
    "\n",
    "\n",
    "def load_raw_df() -> pd.DataFrame:\n",
    "    \"\"\"ØªØ­Ù…ÙŠÙ„ Ø¬Ø¯ÙˆÙ„ ivf_patients Ù…Ù† RAW DB\"\"\"\n",
    "    if not os.path.exists(RAW_DB):\n",
    "        raise FileNotFoundError(f\"RAW DB not found at: {RAW_DB}\")\n",
    "\n",
    "    conn = sqlite3.connect(RAW_DB)\n",
    "    tables = pd.read_sql(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table';\", conn\n",
    "    )[\"name\"].tolist()\n",
    "\n",
    "    if \"ivf_patients\" not in tables:\n",
    "        conn.close()\n",
    "        raise RuntimeError(\"Table 'ivf_patients' not found in RAW DB.\")\n",
    "\n",
    "    df = pd.read_sql(\"SELECT * FROM ivf_patients;\", conn)\n",
    "    conn.close()\n",
    "    logging.info(f\"Loaded {len(df)} rows from raw table.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  CLEANING\n",
    "# ==============================\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Cleaning started...\")\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "    # Drop exact duplicates\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates()\n",
    "    logging.info(f\"Dropped {before - len(df)} duplicate rows.\")\n",
    "\n",
    "    # Strip strings\n",
    "    str_cols = df.select_dtypes(include=\"object\").columns\n",
    "    for c in str_cols:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "    # Numeric missing + winsorization\n",
    "    num_cols = df.select_dtypes(include=[\"float\", \"int\"]).columns\n",
    "    for c in num_cols:\n",
    "        if df[c].isna().any():\n",
    "            med = df[c].median()\n",
    "            df[c] = df[c].fillna(med)\n",
    "            logging.info(f\"Filled NaN in {c} with median={med}.\")\n",
    "        q1 = df[c].quantile(0.01)\n",
    "        q99 = df[c].quantile(0.99)\n",
    "        df[c] = df[c].clip(q1, q99)\n",
    "\n",
    "    # String missing\n",
    "    for c in str_cols:\n",
    "        if df[c].isna().any():\n",
    "            df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "    logging.info(\"Cleaning finished.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  PLACEHOLDER & ID GENERATION\n",
    "# ==============================\n",
    "def apply_placeholder_and_ids(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Applying placeholder rules & generating IDs...\")\n",
    "\n",
    "    # -------- Basic clinical fields --------\n",
    "    if \"risk_level\" not in df.columns:\n",
    "        df[\"risk_level\"] = \"Unknown\"\n",
    "\n",
    "    if \"good_embryos\" not in df.columns:\n",
    "        df[\"good_embryos\"] = 0\n",
    "\n",
    "    if \"embryos_transferred\" not in df.columns:\n",
    "        df[\"embryos_transferred\"] = 0\n",
    "\n",
    "    if \"et_date\" not in df.columns:\n",
    "        df[\"et_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Suggested Waiting Period by risk\n",
    "    df[\"suggested_waiting_period_days\"] = df[\"risk_level\"].map({\n",
    "        \"High\": 90,\n",
    "        \"Medium\": 45,\n",
    "        \"Low\": 30\n",
    "    }).fillna(30)\n",
    "\n",
    "    # Class A Rate\n",
    "    denom = df[\"embryos_transferred\"].replace(0, np.nan)\n",
    "    df[\"class_a_rate\"] = (df[\"good_embryos\"] / denom).fillna(0)\n",
    "\n",
    "    # -------- Doctor --------\n",
    "    if \"doctor_id\" not in df.columns:\n",
    "        if \"doctor_name\" in df.columns:\n",
    "            df[\"doctor_id\"] = (\n",
    "                \"dr_\" +\n",
    "                df[\"doctor_name\"].astype(str)\n",
    "                .str.lower().str.replace(\" \", \"_\")\n",
    "            )\n",
    "        else:\n",
    "            df[\"doctor_id\"] = \"dr_unknown\"\n",
    "    df[\"doctor_id\"] = df[\"doctor_id\"].fillna(\"dr_unknown\")\n",
    "\n",
    "    if \"doctor_recommendation\" not in df.columns:\n",
    "        df[\"doctor_recommendation\"] = \"Unknown\"\n",
    "\n",
    "    # -------- Protocol --------\n",
    "    if \"protocol_type\" not in df.columns:\n",
    "        df[\"protocol_type\"] = \"Unknown\"\n",
    "    if \"stimulation_days\" not in df.columns:\n",
    "        df[\"stimulation_days\"] = 0\n",
    "    if \"total_fsh_dose\" not in df.columns:\n",
    "        df[\"total_fsh_dose\"] = 0\n",
    "    if \"trigger_type\" not in df.columns:\n",
    "        df[\"trigger_type\"] = \"Unknown\"\n",
    "    if \"recommended_protocol\" not in df.columns:\n",
    "        df[\"recommended_protocol\"] = df[\"doctor_recommendation\"]\n",
    "\n",
    "    # protocol_id deterministic based on features\n",
    "    df[\"protocol_id\"] = (\n",
    "        \"prot_\"\n",
    "        + df[\"protocol_type\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "        + \"_d\" + df[\"stimulation_days\"].astype(str)\n",
    "        + \"_dose\" + df[\"total_fsh_dose\"].astype(str)\n",
    "        + \"_trg_\" + df[\"trigger_type\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "    # -------- Outcome --------\n",
    "    if \"response_type\" not in df.columns:\n",
    "        df[\"response_type\"] = \"Unknown\"\n",
    "    if \"failure_reason\" not in df.columns:\n",
    "        df[\"failure_reason\"] = \"Unknown\"\n",
    "\n",
    "    df[\"outcome_id\"] = (\n",
    "        \"out_\"\n",
    "        + df[\"risk_level\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "        + \"_\"\n",
    "        + df[\"response_type\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "    # -------- Embryo --------\n",
    "    if \"fresh_et_stage\" not in df.columns:\n",
    "        df[\"fresh_et_stage\"] = \"Unknown\"\n",
    "    if \"grading\" not in df.columns:\n",
    "        df[\"grading\"] = \"Unknown\"\n",
    "\n",
    "    if \"embryo_id\" not in df.columns:\n",
    "        df[\"embryo_id\"] = (\n",
    "            \"emb_\"\n",
    "            + df[\"fresh_et_stage\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "            + \"_\"\n",
    "            + df[\"grading\"].astype(str).str.lower().str.replace(\" \", \"_\")\n",
    "            + \"_\"\n",
    "            + df.index.astype(str)\n",
    "        )\n",
    "\n",
    "    # -------- M2 & injected_m2 --------\n",
    "    if \"m2_count\" not in df.columns:\n",
    "        df[\"m2_count\"] = 0\n",
    "    else:\n",
    "        df[\"m2_count\"] = df[\"m2_count\"].fillna(0).astype(int)\n",
    "\n",
    "    if \"injected_m2\" not in df.columns:\n",
    "        df[\"injected_m2\"] = df[\"m2_count\"]\n",
    "    else:\n",
    "        df[\"injected_m2\"] = df[\"injected_m2\"].fillna(df[\"m2_count\"]).astype(int)\n",
    "\n",
    "    # -------- Outcome related --------\n",
    "    if \"clinical_pregnancy\" not in df.columns:\n",
    "        df[\"clinical_pregnancy\"] = 0\n",
    "    if \"live_birth\" not in df.columns:\n",
    "        df[\"live_birth\"] = 0\n",
    "    if \"success_probability_score\" not in df.columns:\n",
    "        df[\"success_probability_score\"] = 0.0\n",
    "\n",
    "    # Transfer time id (date text)\n",
    "    df[\"transfer_time_id\"] = pd.to_datetime(\n",
    "        df.get(\"transfer_time_id\", df[\"et_date\"]),\n",
    "        errors=\"coerce\"\n",
    "    ).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    logging.info(\"Placeholder rules & IDs generated.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  LOAD DIMENSIONS\n",
    "# ==============================\n",
    "def load_dimensions_full_refresh(df: pd.DataFrame, conn: sqlite3.Connection):\n",
    "    \"\"\"\n",
    "    FULL REFRESH MODE â€” reload all tables, no duplicate logic.\n",
    "    Use ONLY when doing full rebuild (after DROP TABLE).\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Loading dimensions (FULL REFRESH MODE)...\")\n",
    "\n",
    "    tables = {\n",
    "        \"dim_female\": [\n",
    "            \"female_id\", \"female_age\", \"female_bmi\", \"amh_level\", \"fsh_level\", \"afc\"\n",
    "        ],\n",
    "        \"dim_male\": [\n",
    "            \"male_id\", \"male_age\", \"male_factor\",\n",
    "            \"semen_count_mill_per_ml\", \"motility_percent\", \"morphology_percent\"\n",
    "        ],\n",
    "        \"dim_protocol\": [\n",
    "            \"protocol_id\", \"protocol_type\", \"stimulation_days\",\n",
    "            \"total_fsh_dose\", \"trigger_type\", \"recommended_protocol\"\n",
    "        ],\n",
    "        \"dim_doctor\": [\n",
    "            \"doctor_id\", \"doctor_recommendation\"\n",
    "        ],\n",
    "        \"dim_outcome\": [\n",
    "            \"outcome_id\", \"risk_level\", \"response_type\",\n",
    "            \"suggested_waiting_period_days\", \"failure_reason\"\n",
    "        ],\n",
    "        \"dim_embryo\": [\n",
    "            \"embryo_id\", \"fresh_et_stage\", \"grading\", \"class_a_rate\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for table_name, cols in tables.items():\n",
    "        if not set(cols).issubset(df.columns):\n",
    "            logging.warning(f\"{table_name} skipped â€” missing cols: {set(cols) - set(df.columns)}\")\n",
    "            continue\n",
    "\n",
    "        dim = df[cols].drop_duplicates()\n",
    "        dim.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "        logging.info(f\"{table_name}: inserted {len(dim)} rows.\")\n",
    "\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  LOAD FACTS\n",
    "# ==============================\n",
    "def load_fact_ivf_cycle(df: pd.DataFrame, conn: sqlite3.Connection) -> None:\n",
    "    logging.info(\"Loading fact_ivf_cycle...\")\n",
    "\n",
    "    required = [\n",
    "        \"case_id\", \"female_id\", \"male_id\", \"protocol_id\", \"doctor_id\",\n",
    "        \"outcome_id\", \"et_date\", \"e2_on_trigger\", \"endometrium_thickness\",\n",
    "        \"follicles_18mm\", \"retrieved_oocytes\", \"m2_count\", \"gv_count\",\n",
    "        \"injected_m2\", \"fertilized_oocytes\", \"fertilization_rate\",\n",
    "        \"cleavage_d3\", \"blastocyst_d5\", \"good_embryos\"\n",
    "    ]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        logging.error(f\"Missing columns for fact_ivf_cycle: {missing}\")\n",
    "        return\n",
    "\n",
    "    # Map dates to time_id\n",
    "    time_df = pd.read_sql(\"SELECT time_id, full_date FROM dim_time;\", conn)\n",
    "    if time_df.empty:\n",
    "        logging.error(\"dim_time is empty â€“ cannot link fact_ivf_cycle to time dimension.\")\n",
    "        return\n",
    "\n",
    "    date_to_id = dict(zip(time_df[\"full_date\"], time_df[\"time_id\"]))\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"et_date_clean\"] = pd.to_datetime(tmp[\"et_date\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "    tmp[\"cycle_start_time_id\"] = tmp[\"et_date_clean\"].map(date_to_id)\n",
    "\n",
    "    fact = tmp[[\n",
    "        \"case_id\", \"female_id\", \"male_id\", \"protocol_id\", \"doctor_id\",\n",
    "        \"outcome_id\", \"cycle_start_time_id\", \"e2_on_trigger\",\n",
    "        \"endometrium_thickness\", \"follicles_18mm\", \"retrieved_oocytes\",\n",
    "        \"m2_count\", \"gv_count\", \"injected_m2\", \"fertilized_oocytes\",\n",
    "        \"fertilization_rate\", \"cleavage_d3\", \"blastocyst_d5\", \"good_embryos\"\n",
    "    ]].drop_duplicates(subset=[\"case_id\"])\n",
    "\n",
    "    fact.to_sql(\"fact_ivf_cycle\", conn, if_exists=\"append\", index=False)\n",
    "    logging.info(f\"fact_ivf_cycle: {len(fact)} rows.\")\n",
    "\n",
    "\n",
    "def load_fact_transfer(df: pd.DataFrame, conn: sqlite3.Connection) -> None:\n",
    "    logging.info(\"Loading fact_transfer...\")\n",
    "\n",
    "    required = [\n",
    "        \"case_id\", \"doctor_id\", \"transfer_time_id\", \"embryos_transferred\",\n",
    "        \"pregnancy_test_result\", \"clinical_pregnancy\", \"live_birth\",\n",
    "        \"outcome_id\", \"success_probability_score\"\n",
    "    ]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        logging.warning(f\"Missing columns for fact_transfer: {missing}\")\n",
    "        return\n",
    "\n",
    "    time_df = pd.read_sql(\"SELECT time_id, full_date FROM dim_time;\", conn)\n",
    "    if time_df.empty:\n",
    "        logging.error(\"dim_time is empty â€“ cannot link fact_transfer to time dimension.\")\n",
    "        return\n",
    "\n",
    "    date_to_id = dict(zip(time_df[\"full_date\"], time_df[\"time_id\"]))\n",
    "\n",
    "    tmp = df.copy()\n",
    "    tmp[\"transfer_date_clean\"] = pd.to_datetime(tmp[\"transfer_time_id\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "    tmp[\"transfer_time_fk\"] = tmp[\"transfer_date_clean\"].map(date_to_id)\n",
    "\n",
    "    fact_t = tmp[[\n",
    "        \"case_id\", \"doctor_id\", \"transfer_time_fk\", \"embryos_transferred\",\n",
    "        \"pregnancy_test_result\", \"clinical_pregnancy\", \"live_birth\",\n",
    "        \"outcome_id\", \"success_probability_score\"\n",
    "    ]].drop_duplicates(subset=[\"case_id\"])\n",
    "\n",
    "    fact_t.to_sql(\"fact_transfer\", conn, if_exists=\"append\", index=False)\n",
    "    logging.info(f\"fact_transfer: {len(fact_t)} rows.\")\n",
    "\n",
    "\n",
    "# (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) fact_transfer_embryo â€“ Ù‡Ù†Ø³ÙŠØ¨Ù‡ ÙØ§Ø¶ÙŠ Ù„Ø­Ø¯ Ù…Ø§ ÙŠØ¨Ù‚Ù‰ Ø¹Ù†Ø¯Ù†Ø§ rows Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ embryo\n",
    "\n",
    "\n",
    "def load_dim_time(df: pd.DataFrame, conn: sqlite3.Connection):\n",
    "    \"\"\"\n",
    "    Create dim_time table WITHOUT dropping existing structure.\n",
    "    \"\"\"\n",
    "    logging.info(\"Building dim_time...\")\n",
    "\n",
    "    if \"et_date\" not in df.columns:\n",
    "        logging.error(\"No 'et_date' column â€” cannot build dim_time.\")\n",
    "        return\n",
    "\n",
    "    # Extract unique dates\n",
    "    dates = pd.to_datetime(df[\"et_date\"], errors=\"coerce\").dropna().drop_duplicates()\n",
    "    time_dim = pd.DataFrame({\n",
    "        \"full_date\": dates.dt.strftime(\"%Y-%m-%d\"),\n",
    "        \"day\": dates.dt.day,\n",
    "        \"month\": dates.dt.month,\n",
    "        \"month_name\": dates.dt.month_name(),\n",
    "        \"quarter\": dates.dt.quarter,\n",
    "        \"year\": dates.dt.year,\n",
    "        \"week\": dates.dt.isocalendar().week.astype(int)\n",
    "    })\n",
    "\n",
    "    # Append â€” NOT Replace!\n",
    "    time_dim.to_sql(\"dim_time\", conn, if_exists=\"append\", index=False)\n",
    "    logging.info(f\"dim_time inserted {len(time_dim)} rows.\")\n",
    "\n",
    "    # Make sure time_id exists\n",
    "    chk = pd.read_sql(\"PRAGMA table_info(dim_time);\", conn)\n",
    "    if \"time_id\" not in chk[\"name\"].values:\n",
    "        logging.warning(\"time_id missing â€” regenerating...\")\n",
    "        conn.executescript(\"\"\"\n",
    "            CREATE TABLE dim_time_temp AS\n",
    "            SELECT \n",
    "                ROW_NUMBER() OVER () AS time_id,\n",
    "                full_date, day, month, month_name, quarter, year, week\n",
    "            FROM dim_time;\n",
    "\n",
    "            DROP TABLE dim_time;\n",
    "            ALTER TABLE dim_time_temp RENAME TO dim_time;\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "    logging.info(\"dim_time ready.\")\n",
    "\n",
    "\n",
    "# ==============================\n",
    "#  MAIN\n",
    "# ==============================\n",
    "def run_full_etl():\n",
    "    try:\n",
    "        run_schema_sql()                # 1) rebuild schema\n",
    "        df = load_raw_df()              # 2) raw â†’ df\n",
    "        df = clean_data(df)             # 3) cleaning\n",
    "        df = apply_placeholder_and_ids(df)  # 4) placeholder + IDs\n",
    "\n",
    "        conn = sqlite3.connect(STAR_DB)\n",
    "\n",
    "        load_dimensions_full_refresh(df, conn) # 5) dimensions\n",
    "        load_dim_time(df, conn)       \n",
    "        load_fact_ivf_cycle(df, conn)   # 6) fact_ivf_cycle\n",
    "        load_fact_transfer(df, conn)    # 7) fact_transfer\n",
    "\n",
    "        conn.close()\n",
    "        logging.info(\"ETL COMPLETED SUCCESSFULLY.\")\n",
    "        print(\"ETL COMPLETED SUCCESSFULLY. Check warehouse DB and log file.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"ETL FAILED: {e}\")\n",
    "        print(\"ETL FAILED. Check log file for details:\", e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_etl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1f51e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cid                  name     type  notnull dflt_value  pk\n",
      "0    0           protocol_id     TEXT        0       None   0\n",
      "1    1         protocol_type     TEXT        0       None   0\n",
      "2    2      stimulation_days  INTEGER        0       None   0\n",
      "3    3        total_fsh_dose     REAL        0       None   0\n",
      "4    4          trigger_type     TEXT        0       None   0\n",
      "5    5  recommended_protocol     TEXT        0       None   0\n",
      "                                  protocol_id protocol_type  stimulation_days  \\\n",
      "0       prot_antagonist_d9_dose3598.0_trg_hcg    Antagonist                 9   \n",
      "1            prot_mild_d14_dose4051.0_trg_hcg          Mild                14   \n",
      "2           prot_long_d14_dose4833.0_trg_dual          Long                14   \n",
      "3       prot_antagonist_d9_dose3955.0_trg_hcg    Antagonist                 9   \n",
      "4  prot_short_d11_dose3842.0_trg_gnrh_agonist         Short                11   \n",
      "\n",
      "   total_fsh_dose  trigger_type recommended_protocol  \n",
      "0          3598.0           hCG           Antagonist  \n",
      "1          4051.0           hCG              Agonist  \n",
      "2          4833.0          Dual              Agonist  \n",
      "3          3955.0           hCG           Antagonist  \n",
      "4          3842.0  GnRH agonist           Antagonist  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = STAR_DB\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Show table structure (columns + constraints)\n",
    "table_info = pd.read_sql(\"PRAGMA table_info(dim_protocol);\", conn)\n",
    "print(table_info)\n",
    "\n",
    "# Show existing values in dim_protocol\n",
    "data = pd.read_sql(\"SELECT * FROM dim_protocol;\", conn)\n",
    "print(data.head())\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abca2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force close any active sqlite connection\n",
    "import sqlite3\n",
    "try:\n",
    "    sqlite3.connect(STAR_DB).close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384bb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query: SELECT COUNT(*) FROM dim_protocol; ---\n",
      "   COUNT(*)\n",
      "0      9670\n",
      "\n",
      "--- Query: SELECT COUNT(*) FROM dim_time; ---\n",
      "   COUNT(*)\n",
      "0      3376\n",
      "\n",
      "--- Query: SELECT COUNT(*) FROM fact_transfer; ---\n",
      "   COUNT(*)\n",
      "0     10000\n",
      "\n",
      "--- Query: SELECT * FROM dim_doctor LIMIT 5; ---\n",
      "    doctor_id                              doctor_recommendation\n",
      "0  dr_unknown  Increase gonadotropin dose in next cycle for b...\n",
      "1  dr_unknown  Proceed with embryo freezing for future transfer.\n",
      "2  dr_unknown  Monitor progesterone closely during luteal phase.\n",
      "3  dr_unknown  Consider switching to mild stimulation protoco...\n",
      "4  dr_unknown            Good prognosis, continue same protocol.\n",
      "\n",
      "--- Query: SELECT * FROM fact_ivf_cycle LIMIT 5; ---\n",
      "   cycle_sk     case_id                             female_id  \\\n",
      "0         1  CASE100000  427ba873-37d2-4dd4-9e2f-ee76fd8836fc   \n",
      "1         2  CASE100001  279bd41e-7f8c-4531-8391-19cda6887977   \n",
      "2         3  CASE100002  935afeb1-0f78-4af5-8ae7-a44627e5930e   \n",
      "3         4  CASE100003  35b07eb0-9720-4670-aa50-f3740aeafad3   \n",
      "4         5  CASE100004  c7fbba3e-8a22-4a30-94e5-c20c4a7c03e7   \n",
      "\n",
      "                                male_id  \\\n",
      "0  81d73ebe-eb4e-4a73-a054-fa643c2901a7   \n",
      "1  8b70da19-1cd9-41a3-b201-87e7c77719c1   \n",
      "2  17eb1362-9088-4c4f-8fb5-105b14c27a4e   \n",
      "3  408270cb-828b-4087-9fbb-2dbffd7f5376   \n",
      "4  0c9c5ddf-8267-4f46-b762-88fb3eeeffab   \n",
      "\n",
      "                                  protocol_id   doctor_id  \\\n",
      "0       prot_antagonist_d9_dose3598.0_trg_hcg  dr_unknown   \n",
      "1            prot_mild_d14_dose4051.0_trg_hcg  dr_unknown   \n",
      "2           prot_long_d14_dose4833.0_trg_dual  dr_unknown   \n",
      "3       prot_antagonist_d9_dose3955.0_trg_hcg  dr_unknown   \n",
      "4  prot_short_d11_dose3842.0_trg_gnrh_agonist  dr_unknown   \n",
      "\n",
      "            outcome_id  cycle_start_time_id  e2_on_trigger  \\\n",
      "0  out_moderate_normal                    1         2970.1   \n",
      "1        out_high_poor                    2         1284.1   \n",
      "2        out_high_poor                    3         2718.6   \n",
      "3  out_moderate_normal                    4          678.1   \n",
      "4  out_moderate_normal                    5         1828.8   \n",
      "\n",
      "   endometrium_thickness  follicles_18mm  retrieved_oocytes  m2_count  \\\n",
      "0                    6.8              22                  6         0   \n",
      "1                    6.5              18                  4         0   \n",
      "2                    5.0              18                  4         0   \n",
      "3                    7.9              14                 12         0   \n",
      "4                   12.3               6                 12         0   \n",
      "\n",
      "   gv_count  injected_m2  fertilized_oocytes  fertilization_rate  cleavage_d3  \\\n",
      "0         0            0                   2                0.40            1   \n",
      "1         0            0                   2                0.50            1   \n",
      "2         0            0                   0                0.00            0   \n",
      "3         0            0                   3                0.30            2   \n",
      "4         0            0                   4                0.44            2   \n",
      "\n",
      "   blastocyst_d5  good_embryos  \n",
      "0              1             1  \n",
      "1              0             0  \n",
      "2              0             0  \n",
      "3              1             1  \n",
      "4              0             0  \n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# ====== PATH TO YOUR STAR DATABASE ======\n",
    "db_path = r\"E:\\work\\DEPI\\graduation promax\\data\\warehouse\\ivf_star_schema.db\"\n",
    "\n",
    "# ============ CONNECT =============\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ============ RUN QUERIES =============\n",
    "queries = [\n",
    "    \"SELECT COUNT(*) FROM dim_protocol;\",\n",
    "    \"SELECT COUNT(*) FROM dim_time;\",\n",
    "    \"SELECT COUNT(*) FROM fact_transfer;\",\n",
    "    \"SELECT * FROM dim_doctor LIMIT 5;\",\n",
    "    \"SELECT * FROM fact_ivf_cycle LIMIT 5;\"\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n--- Query: {q} ---\")\n",
    "    try:\n",
    "        df = pd.read_sql(q, conn)   # ðŸ‘ˆ gives neat table view\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "# ============ CLOSE =============\n",
    "conn.close()\n",
    "print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17e412c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case_id', 'et_date', 'female_age', 'female_bmi', 'amh_level',\n",
      "       'fsh_level', 'afc', 'male_age', 'male_factor',\n",
      "       'semen_count_mill_per_ml', 'motility_percent', 'morphology_percent',\n",
      "       'protocol_type', 'stimulation_days', 'total_fsh_dose', 'trigger_type',\n",
      "       'e2_on_trigger', 'endometrium_thickness', 'follicles_18mm',\n",
      "       'retrieved_oocytes', 'mii_count', 'mi_count', 'gv_count',\n",
      "       'injected_mii', 'fertilized_oocytes', 'fertilization_rate',\n",
      "       'cleavage_d3', 'blastocyst_d5', 'good_embryos', 'class_a_rate',\n",
      "       'fresh_et_stage', 'embryos_transferred', 'grading',\n",
      "       'pregnancy_test_result', 'clinical_pregnancy', 'live_birth',\n",
      "       'success_probability_score', 'response_type', 'risk_level',\n",
      "       'recommended_protocol', 'suggested_waiting_period_days',\n",
      "       'failure_reason', 'doctor_recommendation', 'female_id', 'male_id',\n",
      "       'transfer_time_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(r\"E:\\work\\DEPI\\graduation promax\\data\\raw\\ivf_database_updated.db\")\n",
    "df = pd.read_sql(\"SELECT * FROM ivf_patients LIMIT 5;\", conn)\n",
    "print(df.columns)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37a933c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'STAR_DB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlite3\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(STAR_DB)\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRAGMA table_info(dim_time);\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'STAR_DB' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlite3, pandas as pd\n",
    "conn = sqlite3.connect(STAR_DB)\n",
    "\n",
    "df = pd.read_sql(\"PRAGMA table_info(dim_time);\", conn)\n",
    "print(df)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd75ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
