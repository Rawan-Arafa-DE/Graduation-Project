{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae869147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===========================================================\n",
    "#                 CONFIGURATION\n",
    "# ===========================================================\n",
    "BASE_PATH = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\"\n",
    "RAW_DB = fr\"{BASE_PATH}\\data\\raw\\ivf_patients_test.db\"\n",
    "STAR_DB = fr\"{BASE_PATH}\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "SCHEMA_SQL = fr\"{BASE_PATH}\\src\\ETL\\create_star_schema.sql\"\n",
    "LOG_FILE = fr\"{BASE_PATH}\\src\\ETL\\logs\\etl_log_ivf.txt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(STAR_DB), exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "\n",
    "# ===========================================================\n",
    "#                SCHEMA SQL (FULL REFRESH)\n",
    "# ===========================================================\n",
    "def run_schema_sql():\n",
    "    conn = sqlite3.connect(STAR_DB)\n",
    "    with open(SCHEMA_SQL, \"r\", encoding=\"utf-8\") as f:\n",
    "        conn.executescript(f.read())\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    logging.info(\"Schema (fresh) created successfully.\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#                   RAW LOADING\n",
    "# ===========================================================\n",
    "def load_raw_df():\n",
    "    conn = sqlite3.connect(RAW_DB)\n",
    "    df = pd.read_sql(\"SELECT * FROM ivf_patients\", conn)\n",
    "    conn.close()\n",
    "    logging.info(f\"Loaded {len(df)} raw rows.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#                   CLEAN DATA\n",
    "# ===========================================================\n",
    "def clean_data(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#    CHECK REQUIRED COLUMNS (ONLY 3)\n",
    "# ===========================================================\n",
    "def check_required(df):\n",
    "    required = [\"case_id\", \"female_id\", \"male_id\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#   SET NON-CRITICAL IDs TO NULL\n",
    "# ===========================================================\n",
    "def handle_ids(df):\n",
    "    id_cols = [\"protocol_id\", \"outcome_id\", \"embryo_id\"]\n",
    "    for c in id_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "\n",
    "    if \"fresh_et_stage\" not in df.columns:\n",
    "        df[\"fresh_et_stage\"] = None\n",
    "    if \"grading\" not in df.columns:\n",
    "        df[\"grading\"] = None\n",
    "\n",
    "    df[\"transfer_time_id\"] = pd.to_datetime(df.get(\"et_date\", None), errors=\"coerce\") \\\n",
    "                                .dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#     MAP DOCTOR NAME → AUTO INCREMENT doctor_id\n",
    "# ===========================================================\n",
    "def map_doctor_ids(df, conn):\n",
    "    if \"doctor_name\" not in df.columns:\n",
    "        df[\"doctor_name\"] = \"Unknown\"\n",
    "\n",
    "    # Read existing doctors\n",
    "    existing = pd.read_sql(\"SELECT doctor_id, doctor_name FROM dim_doctor;\", conn)\n",
    "    name_to_id = dict(zip(existing[\"doctor_name\"], existing[\"doctor_id\"]))\n",
    "\n",
    "    unique_names = df[\"doctor_name\"].dropna().unique()\n",
    "    new_doctors = [name for name in unique_names if name not in name_to_id]\n",
    "\n",
    "    for name in new_doctors:\n",
    "        cur = conn.execute(\n",
    "            \"INSERT INTO dim_doctor (doctor_name) VALUES (?)\",\n",
    "            (name,)\n",
    "        )\n",
    "        name_to_id[name] = cur.lastrowid\n",
    "\n",
    "    df[\"doctor_id\"] = df[\"doctor_name\"].map(name_to_id)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#   SAFE INSERT → NO DUPLICATION\n",
    "# ===========================================================\n",
    "def insert_or_ignore(table, df_subset, conn):\n",
    "    cols = df_subset.columns.tolist()\n",
    "    placeholders = \",\".join(\"?\" * len(cols))\n",
    "    sql = f\"INSERT OR IGNORE INTO {table} ({','.join(cols)}) VALUES ({placeholders})\"\n",
    "    conn.executemany(sql, df_subset.values.tolist())\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#       DIMENSIONS LOADING\n",
    "# ===========================================================\n",
    "def load_dimensions(df, conn, refresh=True):\n",
    "    dim_tables = {\n",
    "        \"dim_female\":  [\"female_id\",\"female_age\",\"female_bmi\",\"amh_level\",\"fsh_level\",\"afc\"],\n",
    "        \"dim_male\":    [\"male_id\",\"male_age\",\"male_factor\",\"semen_count_mill_per_ml\",\n",
    "                        \"motility_percent\",\"morphology_percent\"],\n",
    "        \"dim_protocol\":[\"protocol_id\",\"protocol_type\",\"stimulation_days\",\n",
    "                        \"total_fsh_dose\",\"trigger_type\",\"recommended_protocol\"],\n",
    "        \"dim_outcome\": [\"outcome_id\",\"risk_level\",\"response_type\",\n",
    "                        \"suggested_waiting_period_days\",\"failure_reason\"],\n",
    "        \"dim_embryo\":  [\"embryo_id\",\"fresh_et_stage\",\"grading\",\"class_a_rate\"]\n",
    "    }\n",
    "\n",
    "    for table, cols in dim_tables.items():\n",
    "        subset = df[cols].drop_duplicates()\n",
    "\n",
    "        if refresh:\n",
    "            subset.to_sql(table, conn, if_exists=\"replace\", index=False)\n",
    "        else:\n",
    "            insert_or_ignore(table, subset, conn)\n",
    "\n",
    "        logging.info(f\"{table}: {len(subset)} processed.\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#       DIM_TIME\n",
    "# ===========================================================\n",
    "def build_dim_time(df, conn):\n",
    "    tmp = pd.to_datetime(df.get(\"et_date\", None), errors=\"coerce\").dropna().drop_duplicates()\n",
    "\n",
    "    time_dim = pd.DataFrame({\n",
    "        \"full_date\": tmp.dt.strftime(\"%Y-%m-%d\"),\n",
    "        \"day\": tmp.dt.day,\n",
    "        \"month\": tmp.dt.month,\n",
    "        \"month_name\": tmp.dt.month_name(),\n",
    "        \"quarter\": tmp.dt.quarter,\n",
    "        \"year\": tmp.dt.year,\n",
    "        \"week\": tmp.dt.isocalendar().week.astype(int)\n",
    "    })\n",
    "\n",
    "    for _, row in time_dim.iterrows():\n",
    "        conn.execute(\"\"\"\n",
    "            INSERT OR IGNORE INTO dim_time\n",
    "            (full_date, day, month, month_name, quarter, year, week)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", tuple(row))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#              FACT TABLES\n",
    "# ===========================================================\n",
    "def load_fact_tables(df, conn):\n",
    "    time_df = pd.read_sql(\"SELECT time_id, full_date FROM dim_time;\", conn)\n",
    "    date_to_id = dict(zip(time_df[\"full_date\"], time_df[\"time_id\"]))\n",
    "\n",
    "    # Fill missing fact numeric columns with 0\n",
    "    fact_needed = [\n",
    "        \"e2_on_trigger\",\"endometrium_thickness\",\"follicles_18mm\",\n",
    "        \"gv_count\",\"injected_m2\",\"fertilized_oocytes\",\n",
    "        \"cleavage_d3\",\"blastocyst_d5\",\"good_embryos\"\n",
    "    ]\n",
    "    for col in fact_needed:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    df[\"cycle_start_time_id\"] = df[\"transfer_time_id\"].map(date_to_id)\n",
    "\n",
    "    fact_cycle = df.drop_duplicates(subset=[\"case_id\"])[[\n",
    "        \"case_id\",\"female_id\",\"male_id\",\"protocol_id\",\"doctor_id\",\"outcome_id\",\n",
    "        \"cycle_start_time_id\",\"e2_on_trigger\",\"endometrium_thickness\",\n",
    "        \"follicles_18mm\",\"retrieved_oocytes\",\"m2_count\",\"gv_count\",\n",
    "        \"injected_m2\",\"fertilized_oocytes\",\"fertilization_rate\",\n",
    "        \"cleavage_d3\",\"blastocyst_d5\",\"good_embryos\"\n",
    "    ]]\n",
    "    insert_or_ignore(\"fact_ivf_cycle\", fact_cycle, conn)\n",
    "\n",
    "    # ---------------- FACT TRANSFER ----------------\n",
    "    if all(col in df.columns for col in [\n",
    "        \"case_id\",\"transfer_time_id\",\"doctor_id\",\"embryos_transferred\"\n",
    "    ]):\n",
    "        tmp = df.drop_duplicates(subset=[\"case_id\"]).copy()\n",
    "        tmp[\"transfer_time_fk\"] = tmp[\"transfer_time_id\"].map(date_to_id)\n",
    "        fact_transfer = tmp[[\n",
    "            \"case_id\",\"transfer_time_fk\",\"doctor_id\",\n",
    "            \"embryos_transferred\",\"pregnancy_test_result\",\n",
    "            \"clinical_pregnancy\",\"live_birth\",\n",
    "            \"outcome_id\",\"success_probability_score\"\n",
    "        ]]\n",
    "        insert_or_ignore(\"fact_transfer\", fact_transfer, conn)\n",
    "\n",
    "    # ---------------- FACT TRANSFER EMBRYO ----------------\n",
    "    try:\n",
    "        existing_transfer = pd.read_sql(\"SELECT transfer_sk, case_id FROM fact_transfer;\", conn)\n",
    "        if not existing_transfer.empty and \"embryo_id\" in df.columns:\n",
    "            df_merge = df.merge(existing_transfer, on=\"case_id\", how=\"inner\")\n",
    "            fact_embryo = df_merge[[\"transfer_sk\",\"embryo_id\"]].drop_duplicates()\n",
    "            insert_or_ignore(\"fact_transfer_embryo\", fact_embryo, conn)\n",
    "    except:\n",
    "        logging.warning(\"fact_transfer_embryo skipped.\")\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#                    MAIN ETL\n",
    "# ===========================================================\n",
    "def run_full_etl(refresh=True):\n",
    "    logging.info(\"===== ETL STARTED =====\")\n",
    "\n",
    "    if refresh:\n",
    "        run_schema_sql()\n",
    "\n",
    "    df = load_raw_df()\n",
    "    df = clean_data(df)\n",
    "\n",
    "    # Required columns check\n",
    "    check_required(df)\n",
    "\n",
    "    # Normalize MII/M2 naming\n",
    "    rename_map = {\"mii_count\": \"m2_count\", \"injected_mii\": \"injected_m2\"}\n",
    "    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "    df = handle_ids(df)\n",
    "\n",
    "    conn = sqlite3.connect(STAR_DB)\n",
    "\n",
    "    # Doctor mapping\n",
    "    df = map_doctor_ids(df, conn)\n",
    "\n",
    "    # Dimensions\n",
    "    load_dimensions(df, conn, refresh=refresh)\n",
    "    build_dim_time(df, conn)\n",
    "    load_fact_tables(df, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    logging.info(\"ETL COMPLETED SUCCESSFULLY.\")\n",
    "    print(\"ETL Done ✔\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_etl(refresh=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d404684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ALL TABLES IN DB ---\n",
      "                    name\n",
      "0        sqlite_sequence\n",
      "1             dim_doctor\n",
      "2               dim_time\n",
      "3         fact_ivf_cycle\n",
      "4          fact_transfer\n",
      "5   fact_transfer_embryo\n",
      "6             dim_female\n",
      "7               dim_male\n",
      "8           dim_protocol\n",
      "9            dim_outcome\n",
      "10            dim_embryo\n",
      "\n",
      "--- ROW COUNTS ---\n",
      "sqlite_sequence           → 4 rows\n",
      "dim_doctor                → 6 rows\n",
      "dim_time                  → 3376 rows\n",
      "fact_ivf_cycle            → 10000 rows\n",
      "fact_transfer             → 10000 rows\n",
      "fact_transfer_embryo      → 10000 rows\n",
      "dim_female                → 10000 rows\n",
      "dim_male                  → 10000 rows\n",
      "dim_protocol              → 10000 rows\n",
      "dim_outcome               → 10000 rows\n",
      "dim_embryo                → 10000 rows\n",
      "\n",
      "--- SAMPLE DATA (LIMIT 3) ---\n",
      "\n",
      "TABLE: sqlite_sequence\n",
      "             name    seq\n",
      "0      dim_doctor      6\n",
      "1        dim_time   3376\n",
      "2  fact_ivf_cycle  10000\n",
      "\n",
      "TABLE: dim_doctor\n",
      "   doctor_id doctor_name                              doctor_recommendation\n",
      "0          1     Unknown  Increase gonadotropin dose in next cycle for b...\n",
      "1          2     Unknown  Proceed with embryo freezing for future transfer.\n",
      "2          3     Unknown  Monitor progesterone closely during luteal phase.\n",
      "\n",
      "TABLE: dim_time\n",
      "   time_id   full_date  day  month month_name  quarter  year  week\n",
      "0        1  2022-03-26   26      3      March        1  2022    12\n",
      "1        2  2016-03-30   30      3      March        1  2016    13\n",
      "2        3  2018-09-06    6      9  September        3  2018    36\n",
      "\n",
      "TABLE: fact_ivf_cycle\n",
      "   cycle_sk     case_id                             female_id  \\\n",
      "0         1  CASE100000  427ba873-37d2-4dd4-9e2f-ee76fd8836fc   \n",
      "1         2  CASE100001  279bd41e-7f8c-4531-8391-19cda6887977   \n",
      "2         3  CASE100002  935afeb1-0f78-4af5-8ae7-a44627e5930e   \n",
      "\n",
      "                                male_id    protocol_id  doctor_id  \\\n",
      "0  81d73ebe-eb4e-4a73-a054-fa643c2901a7  prot_74899d70          1   \n",
      "1  8b70da19-1cd9-41a3-b201-87e7c77719c1  prot_e7ca4e3f          2   \n",
      "2  17eb1362-9088-4c4f-8fb5-105b14c27a4e  prot_db7b1e11          3   \n",
      "\n",
      "     outcome_id  cycle_start_time_id  e2_on_trigger  endometrium_thickness  \\\n",
      "0  out_e814f25d                    1         2970.1                    6.8   \n",
      "1  out_a993d549                    2         1284.1                    6.5   \n",
      "2  out_60d81db5                    3         2718.6                    5.0   \n",
      "\n",
      "   follicles_18mm  retrieved_oocytes  m2_count  gv_count  injected_m2  \\\n",
      "0              22                  6         5         0            5   \n",
      "1              18                  4         4         0            4   \n",
      "2              18                  4         3         0            3   \n",
      "\n",
      "   fertilized_oocytes  fertilization_rate  cleavage_d3  blastocyst_d5  \\\n",
      "0                   2                 0.4            1              1   \n",
      "1                   2                 0.5            1              0   \n",
      "2                   0                 0.0            0              0   \n",
      "\n",
      "   good_embryos  \n",
      "0             1  \n",
      "1             0  \n",
      "2             0  \n",
      "\n",
      "TABLE: fact_transfer\n",
      "   transfer_sk     case_id  transfer_time_fk  doctor_id  embryos_transferred  \\\n",
      "0            1  CASE100000                 1          1                    2   \n",
      "1            2  CASE100001                 2          2                    1   \n",
      "2            3  CASE100002                 3          3                    1   \n",
      "\n",
      "  pregnancy_test_result clinical_pregnancy live_birth    outcome_id  \\\n",
      "0              Negative                 No         No  out_e814f25d   \n",
      "1              Negative                 No         No  out_a993d549   \n",
      "2              Negative                 No         No  out_60d81db5   \n",
      "\n",
      "   success_probability_score  \n",
      "0                      0.402  \n",
      "1                      0.343  \n",
      "2                      0.324  \n",
      "\n",
      "TABLE: fact_transfer_embryo\n",
      "   transfer_sk     embryo_id\n",
      "0            1  emb_a4e3f339\n",
      "1            2  emb_2a111e81\n",
      "2            3  emb_f7c57318\n",
      "\n",
      "TABLE: dim_female\n",
      "                              female_id  female_age  female_bmi  amh_level  \\\n",
      "0  427ba873-37d2-4dd4-9e2f-ee76fd8836fc          35        23.3       1.65   \n",
      "1  279bd41e-7f8c-4531-8391-19cda6887977          32        24.8       0.71   \n",
      "2  935afeb1-0f78-4af5-8ae7-a44627e5930e          36        23.6       0.76   \n",
      "\n",
      "   fsh_level  afc  \n",
      "0       4.66    8  \n",
      "1       3.70    9  \n",
      "2      13.85   13  \n",
      "\n",
      "TABLE: dim_male\n",
      "                                male_id  male_age male_factor  \\\n",
      "0  81d73ebe-eb4e-4a73-a054-fa643c2901a7        41      Normal   \n",
      "1  8b70da19-1cd9-41a3-b201-87e7c77719c1        38      Normal   \n",
      "2  17eb1362-9088-4c4f-8fb5-105b14c27a4e        36         OAT   \n",
      "\n",
      "   semen_count_mill_per_ml  motility_percent  morphology_percent  \n",
      "0                     43.0              20.5                 8.2  \n",
      "1                     58.7              22.1                 2.5  \n",
      "2                     88.2              41.6                 5.4  \n",
      "\n",
      "TABLE: dim_protocol\n",
      "     protocol_id protocol_type  stimulation_days  total_fsh_dose trigger_type  \\\n",
      "0  prot_74899d70    Antagonist                 9            3598          hCG   \n",
      "1  prot_e7ca4e3f          Mild                14            4051          hCG   \n",
      "2  prot_db7b1e11          Long                14            4833         Dual   \n",
      "\n",
      "  recommended_protocol  \n",
      "0           Antagonist  \n",
      "1              Agonist  \n",
      "2              Agonist  \n",
      "\n",
      "TABLE: dim_outcome\n",
      "     outcome_id risk_level response_type  suggested_waiting_period_days  \\\n",
      "0  out_e814f25d   Moderate        Normal                            138   \n",
      "1  out_a993d549       High          Poor                             65   \n",
      "2  out_60d81db5       High          Poor                            170   \n",
      "\n",
      "         failure_reason  \n",
      "0               Unknown  \n",
      "1               Unknown  \n",
      "2  Implantation Failure  \n",
      "\n",
      "TABLE: dim_embryo\n",
      "      embryo_id fresh_et_stage grading  class_a_rate\n",
      "0  emb_a4e3f339             D3       A           1.0\n",
      "1  emb_2a111e81             D5       C           0.0\n",
      "2  emb_f7c57318             D5       C           0.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "conn = sqlite3.connect(DB)\n",
    "\n",
    "# 1️⃣  عرض كل الجداول الموجودة فعليًا:\n",
    "print(\"\\n--- ALL TABLES IN DB ---\")\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(tables)\n",
    "\n",
    "# 2️⃣  عرض عدد الصفوف لكل جدول:\n",
    "print(\"\\n--- ROW COUNTS ---\")\n",
    "for t in tables['name']:\n",
    "    count = pd.read_sql(f\"SELECT COUNT(*) as rows FROM {t};\", conn)\n",
    "    print(f\"{t:<25} → {count['rows'][0]} rows\")\n",
    "\n",
    "# 3️⃣  عرض أول 3 صفوف من كل جدول (لو فيه بيانات):\n",
    "print(\"\\n--- SAMPLE DATA (LIMIT 3) ---\")\n",
    "for t in tables['name']:\n",
    "    try:\n",
    "        sample = pd.read_sql(f\"SELECT * FROM {t} LIMIT 3;\", conn)\n",
    "        print(f\"\\nTABLE: {t}\")\n",
    "        print(sample)\n",
    "    except:\n",
    "        print(f\"\\nTABLE: {t} → Error or no rows\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c987f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cid        name     type  notnull dflt_value  pk\n",
      "0    0     time_id  INTEGER        0       None   1\n",
      "1    1   full_date     TEXT        0       None   0\n",
      "2    2         day  INTEGER        0       None   0\n",
      "3    3       month  INTEGER        0       None   0\n",
      "4    4  month_name     TEXT        0       None   0\n",
      "5    5     quarter  INTEGER        0       None   0\n",
      "6    6        year  INTEGER        0       None   0\n",
      "7    7        week  INTEGER        0       None   0\n",
      "   time_id   full_date  day  month month_name  quarter  year  week\n",
      "0        1  2022-03-26   26      3      March        1  2022    12\n",
      "1        2  2016-03-30   30      3      March        1  2016    13\n",
      "2        3  2018-09-06    6      9  September        3  2018    36\n",
      "3        4  2018-03-05    5      3      March        1  2018    10\n",
      "4        5  2023-03-07    7      3      March        1  2023    10\n"
     ]
    }
   ],
   "source": [
    "import sqlite3, pandas as pd\n",
    "conn = sqlite3.connect(STAR_DB)\n",
    "\n",
    "df = pd.read_sql(\"PRAGMA table_info(dim_time);\", conn)\n",
    "print(df)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM dim_time LIMIT 5;\", conn)\n",
    "print(df)\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296afc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Total Female Patients ---\n",
      "   COUNT(*)\n",
      "0     10000\n",
      "\n",
      "--- Total Male Patients ---\n",
      "   COUNT(*)\n",
      "0     10000\n",
      "\n",
      "--- Protocol Distribution ---\n",
      "  protocol_type  COUNT(*)\n",
      "0    Antagonist      5307\n",
      "1          Long      2519\n",
      "2          Mild       783\n",
      "3         Short      1158\n",
      "\n",
      "--- Success Outcome Counts ---\n",
      "  outcome_id  COUNT(*)\n",
      "0       None     10000\n",
      "\n",
      "--- Sample Dates (dim_time) ---\n",
      "   time_id   full_date  day  month month_name  quarter  year  week\n",
      "0        1  2022-03-26   26      3      March        1  2022    12\n",
      "1        2  2016-03-30   30      3      March        1  2016    13\n",
      "2        3  2018-09-06    6      9  September        3  2018    36\n",
      "3        4  2018-03-05    5      3      March        1  2018    10\n",
      "4        5  2023-03-07    7      3      March        1  2023    10\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "\n",
    "# Connect\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "queries = {\n",
    "    \"Total Female Patients\": \"SELECT COUNT(*) FROM dim_female;\",\n",
    "    \"Total Male Patients\": \"SELECT COUNT(*) FROM dim_male;\",\n",
    "    \"Protocol Distribution\": \"\"\"\n",
    "        SELECT protocol_type, COUNT(*) \n",
    "        FROM dim_protocol\n",
    "        GROUP BY protocol_type;\n",
    "    \"\"\",\n",
    "    \"Success Outcome Counts\": \"\"\"\n",
    "        SELECT outcome_id, COUNT(*) \n",
    "        FROM fact_transfer\n",
    "        GROUP BY outcome_id;\n",
    "    \"\"\",\n",
    "    \"Sample Dates (dim_time)\": \"\"\"\n",
    "        SELECT * FROM dim_time LIMIT 5;\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for title, q in queries.items():\n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    try:\n",
    "        df = pd.read_sql(q, conn)\n",
    "        print(df)\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "conn.close()\n",
    "print(\"\\nConnection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f23ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['case_id', 'et_date', 'female_age', 'female_bmi', 'amh_level',\n",
      "       'fsh_level', 'afc', 'male_age', 'male_factor',\n",
      "       'semen_count_mill_per_ml', 'motility_percent', 'morphology_percent',\n",
      "       'protocol_type', 'stimulation_days', 'total_fsh_dose', 'trigger_type',\n",
      "       'e2_on_trigger', 'endometrium_thickness', 'follicles_18mm',\n",
      "       'retrieved_oocytes', 'mii_count', 'mi_count', 'gv_count',\n",
      "       'injected_mii', 'fertilized_oocytes', 'fertilization_rate',\n",
      "       'cleavage_d3', 'blastocyst_d5', 'good_embryos', 'class_a_rate',\n",
      "       'fresh_et_stage', 'embryos_transferred', 'grading',\n",
      "       'pregnancy_test_result', 'clinical_pregnancy', 'live_birth',\n",
      "       'success_probability_score', 'response_type', 'risk_level',\n",
      "       'recommended_protocol', 'suggested_waiting_period_days',\n",
      "       'failure_reason', 'doctor_recommendation', 'female_id', 'male_id',\n",
      "       'transfer_time_id', 'protocol_id', 'doctor_id', 'outcome_id',\n",
      "       'embryo_id'],\n",
      "      dtype='object')\n",
      "      case_id transfer_time_id  embryos_transferred\n",
      "0  CASE100000       2022-03-26                    2\n",
      "1  CASE100001       2016-03-30                    1\n",
      "2  CASE100002       2018-09-06                    1\n",
      "3  CASE100003       2018-03-05                    1\n",
      "4  CASE100004       2023-03-07                    2\n",
      "embryos_transferred\n",
      "1    5516\n",
      "2    4096\n",
      "3     388\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = load_raw_df()\n",
    "df = clean_data(df)\n",
    "df = apply_placeholder_and_ids(df)\n",
    "print(df.columns)   # عشان نتأكد الأعمدة موجودة\n",
    "\n",
    "print(df[[\"case_id\", \"transfer_time_id\", \"embryos_transferred\"]].head())  # نشوف عينات\n",
    "\n",
    "print(df[\"embryos_transferred\"].value_counts())  # نعرف لو كلها صفر أو فاضية\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Test DB created successfully: ivf_patients_test.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# إنشاء DB جديدة\n",
    "conn = sqlite3.connect(r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\raw\\ivf_patients_test.db\")\n",
    "\n",
    "# الداتا كاملة بنفس الشكل المطلوب للـ ETL\n",
    "data = [\n",
    "    # صف مكرر (للاختبار)\n",
    "    [\"CASE_TEST_001\", \"2023-03-07\", 32, 24.8, 1.2, 5.0, 10, 38, \"Normal\", 55.0, 20.0, 5.0, 4, 4, 2, 0.5, 1, 1.0, \"D5\", 2, \"B\", \"Negative\", 0, 0, 0.76, \"Poor\", \"High\", \"Antagonist\", 90, \"Unknown\", \"Good response\"],\n",
    "    [\"CASE_TEST_001\", \"2023-03-07\", 32, 24.8, 1.2, 5.0, 10, 38, \"Normal\", 55.0, 20.0, 5.0, 4, 4, 2, 0.5, 1, 1.0, \"D5\", 2, \"B\", \"Negative\", 0, 0, 0.76, \"Poor\", \"High\", \"Antagonist\", 90, \"Unknown\", \"Good response\"],\n",
    "\n",
    "    # صف جديد\n",
    "    [\"CASE_TEST_002\", \"2022-11-15\", 30, 22.5, 0.9, 4.3, 12, 41, \"OAT\", 40.0, 18.0, 6.0, 5, 5, 3, 0.6, 2, 0.8, \"D3\", 1, \"C\", \"Positive\", 1, 0, 0.88, \"Normal\", \"Medium\", \"Mild\", 45, \"Implantation Failure\", \"Monitor closely\"],\n",
    "\n",
    "    # صف جديد (نصف البيانات ناقص → اختبار null handling)\n",
    "    [\"CASE_TEST_003\", None, 29, None, None, 3.1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 0.00, None, None, None, None, None, None]\n",
    "]\n",
    "\n",
    "columns = [\n",
    "    \"case_id\",\"et_date\",\"female_age\",\"female_bmi\",\"amh_level\",\"fsh_level\",\"afc\",\n",
    "    \"male_age\",\"male_factor\",\"semen_count_mill_per_ml\",\"motility_percent\",\"morphology_percent\",\n",
    "    \"retrieved_oocytes\",\"mii_count\",\"num_embryos_generated\",\"fertilization_rate\",\n",
    "    \"good_embryos\",\"class_a_rate\",\"fresh_et_stage\",\"embryos_transferred\",\"grading\",\n",
    "    \"pregnancy_test_result\",\"clinical_pregnancy\",\"live_birth\",\"success_probability_score\",\n",
    "    \"response_type\",\"risk_level\",\"recommended_protocol\",\"suggested_waiting_period_days\",\n",
    "    \"failure_reason\",\"doctor_recommendation\"\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.to_sql(\"ivf_patients\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n",
    "print(\"✔ Test DB created successfully: ivf_patients_test.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cb598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>et_date</th>\n",
       "      <th>female_age</th>\n",
       "      <th>female_bmi</th>\n",
       "      <th>amh_level</th>\n",
       "      <th>fsh_level</th>\n",
       "      <th>afc</th>\n",
       "      <th>male_age</th>\n",
       "      <th>male_factor</th>\n",
       "      <th>semen_count_mill_per_ml</th>\n",
       "      <th>...</th>\n",
       "      <th>pregnancy_test_result</th>\n",
       "      <th>clinical_pregnancy</th>\n",
       "      <th>live_birth</th>\n",
       "      <th>success_probability_score</th>\n",
       "      <th>response_type</th>\n",
       "      <th>risk_level</th>\n",
       "      <th>recommended_protocol</th>\n",
       "      <th>suggested_waiting_period_days</th>\n",
       "      <th>failure_reason</th>\n",
       "      <th>doctor_recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASE_TEST_001</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>32</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Poor</td>\n",
       "      <td>High</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Good response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASE_TEST_001</td>\n",
       "      <td>2023-03-07</td>\n",
       "      <td>32</td>\n",
       "      <td>24.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>Poor</td>\n",
       "      <td>High</td>\n",
       "      <td>Antagonist</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Good response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASE_TEST_002</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>30</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>OAT</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Mild</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Implantation Failure</td>\n",
       "      <td>Monitor closely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASE_TEST_003</td>\n",
       "      <td>None</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         case_id     et_date  female_age  female_bmi  amh_level  fsh_level  \\\n",
       "0  CASE_TEST_001  2023-03-07          32        24.8        1.2        5.0   \n",
       "1  CASE_TEST_001  2023-03-07          32        24.8        1.2        5.0   \n",
       "2  CASE_TEST_002  2022-11-15          30        22.5        0.9        4.3   \n",
       "3  CASE_TEST_003        None          29         NaN        NaN        3.1   \n",
       "\n",
       "    afc  male_age male_factor  semen_count_mill_per_ml  ...  \\\n",
       "0  10.0      38.0      Normal                     55.0  ...   \n",
       "1  10.0      38.0      Normal                     55.0  ...   \n",
       "2  12.0      41.0         OAT                     40.0  ...   \n",
       "3   NaN       NaN        None                      NaN  ...   \n",
       "\n",
       "   pregnancy_test_result  clinical_pregnancy  live_birth  \\\n",
       "0               Negative                 0.0         0.0   \n",
       "1               Negative                 0.0         0.0   \n",
       "2               Positive                 1.0         0.0   \n",
       "3                   None                 NaN         NaN   \n",
       "\n",
       "   success_probability_score  response_type  risk_level  recommended_protocol  \\\n",
       "0                       0.76           Poor        High            Antagonist   \n",
       "1                       0.76           Poor        High            Antagonist   \n",
       "2                       0.88         Normal      Medium                  Mild   \n",
       "3                       0.00           None        None                  None   \n",
       "\n",
       "   suggested_waiting_period_days        failure_reason  doctor_recommendation  \n",
       "0                           90.0               Unknown          Good response  \n",
       "1                           90.0               Unknown          Good response  \n",
       "2                           45.0  Implantation Failure        Monitor closely  \n",
       "3                            NaN                  None                   None  \n",
       "\n",
       "[4 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the database and display full table\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "db_path = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\raw\\ivf_patients_test.db\"\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM ivf_patients\", conn)\n",
    "conn.close()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c30c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Excel saved at: E:\\work\\DEPI\\graduation promax\\data\\raw\\raw_database_dump.xlsx\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# 1) PATHS\n",
    "# ================================\n",
    "db_path = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\raw\\ivf_database_updated.db\"\n",
    "excel_output = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\raw\\raw_database_dump.xlsx\"\n",
    "\n",
    "# ================================\n",
    "# 2) CONNECT TO DB\n",
    "# ================================\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# ================================\n",
    "# 3) READ TABLE NAMES\n",
    "# ================================\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'\",\n",
    "    conn\n",
    ")\n",
    "\n",
    "table_list = tables[\"name\"].tolist()\n",
    "\n",
    "# ================================\n",
    "# 4) EXPORT TO EXCEL\n",
    "# ================================\n",
    "with pd.ExcelWriter(excel_output, engine=\"openpyxl\") as writer:\n",
    "    for tbl in table_list:\n",
    "        df = pd.read_sql(f\"SELECT * FROM {tbl}\", conn)\n",
    "        df.to_excel(writer, sheet_name=tbl[:31], index=False)  # Excel sheet name limit\n",
    "\n",
    "# ================================\n",
    "# 5) CLOSE CONNECTION\n",
    "# ================================\n",
    "conn.close()\n",
    "\n",
    "print(\"Done! Excel saved at:\", excel_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd1d69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Done ✔\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import sqlite3\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ===========================================================\n",
    "#                 CONFIGURATION\n",
    "# ===========================================================\n",
    "BASE_PATH = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\"\n",
    "RAW_DB = fr\"{BASE_PATH}\\data\\raw\\ivf_database_updated.db\"\n",
    "STAR_DB = fr\"{BASE_PATH}\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "SCHEMA_SQL = fr\"{BASE_PATH}\\src\\ETL\\create_star_schema.sql\"\n",
    "LOG_FILE = fr\"{BASE_PATH}\\src\\ETL\\logs\\etl_log_ivf.txt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(STAR_DB), exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"ivf_etl\")\n",
    "\n",
    "# ===========================================================\n",
    "#                SCHEMA SQL (FULL REFRESH)\n",
    "# ===========================================================\n",
    "def run_schema_sql():\n",
    "    try:\n",
    "        conn = sqlite3.connect(STAR_DB)\n",
    "        with open(SCHEMA_SQL, \"r\", encoding=\"utf-8\") as f:\n",
    "            conn.executescript(f.read())\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        logging.info(\"Schema (fresh) created successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.exception(\"run_schema_sql FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#                   RAW LOADING\n",
    "# ===========================================================\n",
    "def load_raw_df():\n",
    "    try:\n",
    "        conn = sqlite3.connect(RAW_DB)\n",
    "        df = pd.read_sql(\"SELECT * FROM ivf_patients\", conn)\n",
    "        conn.close()\n",
    "        logging.info(f\"Loaded {len(df)} raw rows.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.exception(\"load_raw_df FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#                   CLEAN DATA\n",
    "# ===========================================================\n",
    "def clean_data(df):\n",
    "    try:\n",
    "        df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "        df = df.drop_duplicates()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.exception(\"clean_data FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#    CHECK REQUIRED COLUMNS (ONLY 3)\n",
    "# ===========================================================\n",
    "def check_required(df):\n",
    "    required = [\"case_id\", \"female_id\", \"male_id\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        logging.error(f\"Missing required columns: {missing}\")\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# ===========================================================\n",
    "#   GENERATE ID IF MISSING (preserve existing IDs)\n",
    "# ===========================================================\n",
    "def gen_if_missing_series(series, prefix):\n",
    "    # returns a series where missing/empty entries are replaced with prefix_uuid\n",
    "    def gen(v):\n",
    "        if pd.isna(v) or str(v).strip() == \"\":\n",
    "            return f\"{prefix}_{uuid.uuid4().hex[:8]}\"\n",
    "        return v\n",
    "    return series.apply(gen)\n",
    "\n",
    "# ===========================================================\n",
    "#   SET NON-CRITICAL IDs TO NULL + GEN FOR protocol/outcome/embryo\n",
    "#   IMPORTANT: generate only when refresh=True (full refresh).\n",
    "# ===========================================================\n",
    "def handle_ids(df, refresh):\n",
    "    try:\n",
    "        # ensure columns exist\n",
    "        for c in [\"protocol_id\", \"outcome_id\", \"embryo_id\"]:\n",
    "            if c not in df.columns:\n",
    "                df[c] = None\n",
    "\n",
    "        # generate IDs only if refresh == True (full refresh)\n",
    "        if refresh:\n",
    "            df[\"protocol_id\"] = gen_if_missing_series(df[\"protocol_id\"], \"prot\")\n",
    "            df[\"outcome_id\"] = gen_if_missing_series(df[\"outcome_id\"], \"out\")\n",
    "            df[\"embryo_id\"] = gen_if_missing_series(df[\"embryo_id\"], \"emb\")\n",
    "        else:\n",
    "            # incremental mode: do NOT generate new IDs here\n",
    "            # keep any existing IDs from raw; leave None if missing\n",
    "            pass\n",
    "\n",
    "        # optional columns\n",
    "        if \"fresh_et_stage\" not in df.columns:\n",
    "            df[\"fresh_et_stage\"] = None\n",
    "        if \"grading\" not in df.columns:\n",
    "            df[\"grading\"] = None\n",
    "\n",
    "        # transfer_time_id from et_date (string YYYY-MM-DD) or None\n",
    "        df[\"transfer_time_id\"] = pd.to_datetime(df.get(\"et_date\", None), errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.exception(\"handle_ids FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#     MAP DOCTOR NAME → AUTO INCREMENT doctor_id + recommendation\n",
    "# ===========================================================\n",
    "def map_doctor_ids(df, conn):\n",
    "    try:\n",
    "        # Ensure both columns exist\n",
    "        if \"doctor_name\" not in df.columns:\n",
    "            df[\"doctor_name\"] = \"Unknown\"\n",
    "\n",
    "        if \"doctor_recommendation\" not in df.columns:\n",
    "            df[\"doctor_recommendation\"] = None\n",
    "\n",
    "        # Ensure table exists\n",
    "        conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS dim_doctor (\n",
    "                doctor_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                doctor_name TEXT,\n",
    "                doctor_recommendation TEXT,\n",
    "                UNIQUE (doctor_name, doctor_recommendation)\n",
    "            )\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        # Read existing doctor combinations\n",
    "        existing = pd.read_sql(\n",
    "            \"SELECT doctor_id, doctor_name, doctor_recommendation FROM dim_doctor\",\n",
    "            conn\n",
    "        )\n",
    "\n",
    "        # Build natural key: name + recommendation\n",
    "        existing[\"nat_key\"] = (\n",
    "            existing[\"doctor_name\"].astype(str).str.strip()\n",
    "            + \"|\" +\n",
    "            existing[\"doctor_recommendation\"].astype(str).str.strip()\n",
    "        )\n",
    "\n",
    "        df[\"nat_key\"] = (\n",
    "            df[\"doctor_name\"].astype(str).str.strip()\n",
    "            + \"|\" +\n",
    "            df[\"doctor_recommendation\"].astype(str).str.strip()\n",
    "        )\n",
    "\n",
    "        # Map existing nat_keys → doctor_id\n",
    "        nat_to_id = dict(zip(existing[\"nat_key\"], existing[\"doctor_id\"]))\n",
    "\n",
    "        # Identify new doctor rows\n",
    "        new_rows = df.loc[~df[\"nat_key\"].isin(nat_to_id)][\n",
    "            [\"doctor_name\", \"doctor_recommendation\", \"nat_key\"]\n",
    "        ].drop_duplicates()\n",
    "\n",
    "        # Insert new rows\n",
    "        for _, row in new_rows.iterrows():\n",
    "            cur = conn.execute(\n",
    "                \"INSERT OR IGNORE INTO dim_doctor (doctor_name, doctor_recommendation) VALUES (?, ?)\",\n",
    "                (row[\"doctor_name\"], row[\"doctor_recommendation\"])\n",
    "            )\n",
    "            conn.commit()\n",
    "\n",
    "            # Retrieve id after insert\n",
    "            result = conn.execute(\n",
    "                \"SELECT doctor_id FROM dim_doctor WHERE doctor_name = ? AND doctor_recommendation = ?\",\n",
    "                (row[\"doctor_name\"], row[\"doctor_recommendation\"])\n",
    "            ).fetchone()\n",
    "            if result:\n",
    "                doctor_id = result[0]\n",
    "            else:\n",
    "                continue  \n",
    "\n",
    "            nat_to_id[row[\"nat_key\"]] = doctor_id\n",
    "\n",
    "        # Assign final doctor_ids\n",
    "        df[\"doctor_id\"] = df[\"nat_key\"].map(nat_to_id)\n",
    "\n",
    "        logging.info(f\"Mapped {len(nat_to_id)} unique doctor entries.\")\n",
    "        return df\n",
    "\n",
    "    except Exception:\n",
    "        logging.exception(\"map_doctor_ids FAILED\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#   SAFE INSERT → NO DUPLICATION (helper)\n",
    "# ===========================================================\n",
    "def insert_or_ignore(table, df_subset, conn):\n",
    "    if df_subset is None or df_subset.shape[0] == 0:\n",
    "        return\n",
    "    cols = df_subset.columns.tolist()\n",
    "    placeholders = \",\".join(\"?\" * len(cols))\n",
    "    sql = f\"INSERT OR IGNORE INTO {table} ({','.join(cols)}) VALUES ({placeholders})\"\n",
    "    try:\n",
    "        conn.executemany(sql, df_subset.values.tolist())\n",
    "        conn.commit()\n",
    "    except Exception:\n",
    "        logging.exception(f\"insert_or_ignore FAILED for {table}\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#       DIMENSIONS LOADING (kept behavior; fallback on error)\n",
    "# ===========================================================\n",
    "def load_dimensions(df, conn, refresh=True):\n",
    "    dim_tables = {\n",
    "        \"dim_female\":  [\"female_id\",\"female_age\",\"female_bmi\",\"amh_level\",\"fsh_level\",\"afc\"],\n",
    "        \"dim_male\":    [\"male_id\",\"male_age\",\"male_factor\",\"semen_count_mill_per_ml\",\n",
    "                        \"motility_percent\",\"morphology_percent\"],\n",
    "        \"dim_protocol\":[\"protocol_id\",\"protocol_type\",\"stimulation_days\",\n",
    "                        \"total_fsh_dose\",\"trigger_type\",\"recommended_protocol\"],\n",
    "        \"dim_outcome\": [\"outcome_id\",\"risk_level\",\"response_type\",\n",
    "                        \"suggested_waiting_period_days\",\"failure_reason\"],\n",
    "        \"dim_embryo\":  [\"embryo_id\",\"fresh_et_stage\",\"grading\",\"class_a_rate\"]\n",
    "    }\n",
    "\n",
    "    for table, cols in dim_tables.items():\n",
    "\n",
    "        # 🔒 ضمان وجود كل الأعمدة المطلوبة حتى لو مش موجودة في الـ raw\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                df[c] = None\n",
    "\n",
    "        subset = df[cols].drop_duplicates()\n",
    "\n",
    "        try:\n",
    "            if refresh:\n",
    "                # original replace behavior\n",
    "                subset.to_sql(table, conn, if_exists=\"replace\", index=False)\n",
    "            else:\n",
    "                # incremental: safe insert-or-ignore\n",
    "                insert_or_ignore(table, subset, conn)\n",
    "\n",
    "            logging.info(f\"{table}: {len(subset)} processed.\")\n",
    "\n",
    "        except sqlite3.IntegrityError:\n",
    "            # fallback: insert rows one by one\n",
    "            logging.warning(f\"{table}: IntegrityError on bulk insert — falling back to row-by-row INSERT OR IGNORE\")\n",
    "            placeholders = \",\".join(\"?\" * len(cols))\n",
    "            columns = \",\".join(cols)\n",
    "            sql = f\"INSERT OR IGNORE INTO {table} ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "            cur = conn.cursor()\n",
    "            for row in subset.values.tolist():\n",
    "                try:\n",
    "                    cur.execute(sql, row)\n",
    "                except Exception:\n",
    "                    logging.exception(f\"{table}: failed to insert row {row}\")\n",
    "            conn.commit()\n",
    "\n",
    "        except Exception:\n",
    "            logging.exception(f\"load_dimensions failed for {table}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "#       DIM_TIME\n",
    "# ===========================================================\n",
    "def build_dim_time(df, conn):\n",
    "    try:\n",
    "        tmp = pd.to_datetime(df.get(\"et_date\", None), errors=\"coerce\").dropna().drop_duplicates()\n",
    "\n",
    "        time_dim = pd.DataFrame({\n",
    "            \"full_date\": tmp.dt.strftime(\"%Y-%m-%d\"),\n",
    "            \"day\": tmp.dt.day,\n",
    "            \"month\": tmp.dt.month,\n",
    "            \"month_name\": tmp.dt.month_name(),\n",
    "            \"quarter\": tmp.dt.quarter,\n",
    "            \"year\": tmp.dt.year,\n",
    "            \"week\": tmp.dt.isocalendar().week.astype(int)\n",
    "        })\n",
    "\n",
    "        for _, row in time_dim.iterrows():\n",
    "            conn.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO dim_time\n",
    "                (full_date, day, month, month_name, quarter, year, week)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", tuple(row))\n",
    "        conn.commit()\n",
    "        logging.info(\"build_dim_time done.\")\n",
    "    except Exception:\n",
    "        logging.exception(\"build_dim_time FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#              FACT TABLES\n",
    "# ===========================================================\n",
    "def load_fact_tables(df, conn):\n",
    "    try:\n",
    "        time_df = pd.read_sql(\"SELECT time_id, full_date FROM dim_time;\", conn)\n",
    "        date_to_id = dict(zip(time_df[\"full_date\"], time_df[\"time_id\"]))\n",
    "\n",
    "        # Fill missing fact numeric columns with 0\n",
    "        fact_needed = [\n",
    "            \"e2_on_trigger\",\"endometrium_thickness\",\"follicles_18mm\",\n",
    "            \"gv_count\",\"injected_m2\",\"fertilized_oocytes\",\n",
    "            \"cleavage_d3\",\"blastocyst_d5\",\"good_embryos\"\n",
    "        ]\n",
    "        for col in fact_needed:\n",
    "            if col not in df.columns:\n",
    "                df[col] = 0\n",
    "\n",
    "        df[\"cycle_start_time_id\"] = df[\"transfer_time_id\"].map(date_to_id)\n",
    "\n",
    "        fact_cycle = df.drop_duplicates(subset=[\"case_id\"])[[\n",
    "            \"case_id\",\"female_id\",\"male_id\",\"protocol_id\",\"doctor_id\",\"outcome_id\",\n",
    "            \"cycle_start_time_id\",\"e2_on_trigger\",\"endometrium_thickness\",\n",
    "            \"follicles_18mm\",\"retrieved_oocytes\",\"m2_count\",\"gv_count\",\n",
    "            \"injected_m2\",\"fertilized_oocytes\",\"fertilization_rate\",\n",
    "            \"cleavage_d3\",\"blastocyst_d5\",\"good_embryos\"\n",
    "        ]]\n",
    "        insert_or_ignore(\"fact_ivf_cycle\", fact_cycle, conn)\n",
    "\n",
    "        # ---------------- FACT TRANSFER ----------------\n",
    "        if all(col in df.columns for col in [\n",
    "            \"case_id\",\"transfer_time_id\",\"doctor_id\",\"embryos_transferred\"\n",
    "        ]):\n",
    "            tmp = df.drop_duplicates(subset=[\"case_id\"]).copy()\n",
    "            tmp[\"transfer_time_fk\"] = tmp[\"transfer_time_id\"].map(date_to_id)\n",
    "            fact_transfer = tmp[[\n",
    "                \"case_id\",\"transfer_time_fk\",\"doctor_id\",\n",
    "                \"embryos_transferred\",\"pregnancy_test_result\",\n",
    "                \"clinical_pregnancy\",\"live_birth\",\n",
    "                \"outcome_id\",\"success_probability_score\"\n",
    "            ]]\n",
    "            insert_or_ignore(\"fact_transfer\", fact_transfer, conn)\n",
    "\n",
    "        # ---------------- FACT TRANSFER EMBRYO ----------------\n",
    "        try:\n",
    "            existing_transfer = pd.read_sql(\"SELECT transfer_sk, case_id FROM fact_transfer;\", conn)\n",
    "            if not existing_transfer.empty and \"embryo_id\" in df.columns:\n",
    "                df_merge = df.merge(existing_transfer, on=\"case_id\", how=\"inner\")\n",
    "                fact_embryo = df_merge[[\"transfer_sk\",\"embryo_id\"]].drop_duplicates()\n",
    "                insert_or_ignore(\"fact_transfer_embryo\", fact_embryo, conn)\n",
    "        except Exception:\n",
    "            logging.exception(\"fact_transfer_embryo skipped.\")\n",
    "    except Exception:\n",
    "        logging.exception(\"load_fact_tables FAILED\")\n",
    "        raise\n",
    "\n",
    "# ===========================================================\n",
    "#                    MAIN ETL\n",
    "# ===========================================================\n",
    "def run_full_etl(refresh=True):\n",
    "    logging.info(\"===== ETL STARTED =====\")\n",
    "    try:\n",
    "        if refresh:\n",
    "            run_schema_sql()\n",
    "\n",
    "        df = load_raw_df()\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        # === AUTO-GENERATE female_id / male_id IF MISSING ===\n",
    "        if \"female_id\" not in df.columns:\n",
    "            df[\"female_id\"] = [\"F_\" + uuid.uuid4().hex[:8] for _ in range(len(df))]\n",
    "\n",
    "        if \"male_id\" not in df.columns:\n",
    "            df[\"male_id\"] = [\"M_\" + uuid.uuid4().hex[:8] for _ in range(len(df))]\n",
    "\n",
    "\n",
    "        # Required columns check\n",
    "        check_required(df)\n",
    "\n",
    "        # Normalize MII/M2 naming (safeguard)\n",
    "        rename_map = {\"mii_count\": \"m2_count\", \"injected_mii\": \"injected_m2\"}\n",
    "        df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "        # IDs and optional fields — pass refresh so incremental won't generate IDs\n",
    "        df = handle_ids(df, refresh)\n",
    "\n",
    "        conn = sqlite3.connect(STAR_DB)\n",
    "\n",
    "        # Map doctor (auto inc) and recommendation handling\n",
    "        df = map_doctor_ids(df, conn)\n",
    "\n",
    "        # Dimensions\n",
    "        load_dimensions(df, conn, refresh=refresh)\n",
    "\n",
    "        # Time dimension\n",
    "        build_dim_time(df, conn)\n",
    "\n",
    "        # Fact tables\n",
    "        load_fact_tables(df, conn)\n",
    "\n",
    "        conn.close()\n",
    "        logging.info(\"ETL COMPLETED SUCCESSFULLY.\")\n",
    "        print(\"ETL Done ✔\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.exception(\"run_full_etl FAILED\")\n",
    "        print(f\"ETL FAILED: {e}\")\n",
    "        return False\n",
    "\n",
    "# ===========================================================\n",
    "#                      RUN\n",
    "# ===========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_etl(refresh=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ALL TABLES IN DB ---\n",
      "                    name\n",
      "0        sqlite_sequence\n",
      "1             dim_doctor\n",
      "2               dim_time\n",
      "3         fact_ivf_cycle\n",
      "4          fact_transfer\n",
      "5   fact_transfer_embryo\n",
      "6             dim_female\n",
      "7               dim_male\n",
      "8           dim_protocol\n",
      "9            dim_outcome\n",
      "10            dim_embryo\n",
      "\n",
      "--- ROW COUNTS ---\n",
      "sqlite_sequence           → 4 rows\n",
      "dim_doctor                → 6 rows\n",
      "dim_time                  → 3376 rows\n",
      "fact_ivf_cycle            → 10000 rows\n",
      "fact_transfer             → 10000 rows\n",
      "fact_transfer_embryo      → 10000 rows\n",
      "dim_female                → 10000 rows\n",
      "dim_male                  → 10000 rows\n",
      "dim_protocol              → 10000 rows\n",
      "dim_outcome               → 10000 rows\n",
      "dim_embryo                → 10000 rows\n",
      "\n",
      "--- SAMPLE DATA (LIMIT 3) ---\n",
      "\n",
      "TABLE: sqlite_sequence\n",
      "             name    seq\n",
      "0      dim_doctor      6\n",
      "1        dim_time   3376\n",
      "2  fact_ivf_cycle  10000\n",
      "\n",
      "TABLE: dim_doctor\n",
      "   doctor_id doctor_name                              doctor_recommendation\n",
      "0          1     Unknown  Increase gonadotropin dose in next cycle for b...\n",
      "1          2     Unknown  Proceed with embryo freezing for future transfer.\n",
      "2          3     Unknown  Monitor progesterone closely during luteal phase.\n",
      "\n",
      "TABLE: dim_time\n",
      "   time_id   full_date  day  month month_name  quarter  year  week\n",
      "0        1  2022-03-26   26      3      March        1  2022    12\n",
      "1        2  2016-03-30   30      3      March        1  2016    13\n",
      "2        3  2018-09-06    6      9  September        3  2018    36\n",
      "\n",
      "TABLE: fact_ivf_cycle\n",
      "   cycle_sk     case_id                             female_id  \\\n",
      "0         1  CASE100000  427ba873-37d2-4dd4-9e2f-ee76fd8836fc   \n",
      "1         2  CASE100001  279bd41e-7f8c-4531-8391-19cda6887977   \n",
      "2         3  CASE100002  935afeb1-0f78-4af5-8ae7-a44627e5930e   \n",
      "\n",
      "                                male_id    protocol_id  doctor_id  \\\n",
      "0  81d73ebe-eb4e-4a73-a054-fa643c2901a7  prot_c8a879b2          1   \n",
      "1  8b70da19-1cd9-41a3-b201-87e7c77719c1  prot_8f44ccf8          2   \n",
      "2  17eb1362-9088-4c4f-8fb5-105b14c27a4e  prot_8e0ce0bd          3   \n",
      "\n",
      "     outcome_id  cycle_start_time_id  e2_on_trigger  endometrium_thickness  \\\n",
      "0  out_1e0526b3                    1         2970.1                    6.8   \n",
      "1  out_76cb8ffb                    2         1284.1                    6.5   \n",
      "2  out_fd613743                    3         2718.6                    5.0   \n",
      "\n",
      "   follicles_18mm  retrieved_oocytes  m2_count  gv_count  injected_m2  \\\n",
      "0              22                  6         5         0            5   \n",
      "1              18                  4         4         0            4   \n",
      "2              18                  4         3         0            3   \n",
      "\n",
      "   fertilized_oocytes  fertilization_rate  cleavage_d3  blastocyst_d5  \\\n",
      "0                   2                 0.4            1              1   \n",
      "1                   2                 0.5            1              0   \n",
      "2                   0                 0.0            0              0   \n",
      "\n",
      "   good_embryos  \n",
      "0             1  \n",
      "1             0  \n",
      "2             0  \n",
      "\n",
      "TABLE: fact_transfer\n",
      "   transfer_sk     case_id  transfer_time_fk  doctor_id  embryos_transferred  \\\n",
      "0            1  CASE100000                 1          1                    2   \n",
      "1            2  CASE100001                 2          2                    1   \n",
      "2            3  CASE100002                 3          3                    1   \n",
      "\n",
      "  pregnancy_test_result clinical_pregnancy live_birth    outcome_id  \\\n",
      "0              Negative                 No         No  out_1e0526b3   \n",
      "1              Negative                 No         No  out_76cb8ffb   \n",
      "2              Negative                 No         No  out_fd613743   \n",
      "\n",
      "   success_probability_score  \n",
      "0                      0.402  \n",
      "1                      0.343  \n",
      "2                      0.324  \n",
      "\n",
      "TABLE: fact_transfer_embryo\n",
      "   transfer_sk     embryo_id\n",
      "0            1  emb_d3c7cbf1\n",
      "1            2  emb_3ca809f9\n",
      "2            3  emb_74c5aa80\n",
      "\n",
      "TABLE: dim_female\n",
      "                              female_id  female_age  female_bmi  amh_level  \\\n",
      "0  427ba873-37d2-4dd4-9e2f-ee76fd8836fc          35        23.3       1.65   \n",
      "1  279bd41e-7f8c-4531-8391-19cda6887977          32        24.8       0.71   \n",
      "2  935afeb1-0f78-4af5-8ae7-a44627e5930e          36        23.6       0.76   \n",
      "\n",
      "   fsh_level  afc  \n",
      "0       4.66    8  \n",
      "1       3.70    9  \n",
      "2      13.85   13  \n",
      "\n",
      "TABLE: dim_male\n",
      "                                male_id  male_age male_factor  \\\n",
      "0  81d73ebe-eb4e-4a73-a054-fa643c2901a7        41      Normal   \n",
      "1  8b70da19-1cd9-41a3-b201-87e7c77719c1        38      Normal   \n",
      "2  17eb1362-9088-4c4f-8fb5-105b14c27a4e        36         OAT   \n",
      "\n",
      "   semen_count_mill_per_ml  motility_percent  morphology_percent  \n",
      "0                     43.0              20.5                 8.2  \n",
      "1                     58.7              22.1                 2.5  \n",
      "2                     88.2              41.6                 5.4  \n",
      "\n",
      "TABLE: dim_protocol\n",
      "     protocol_id protocol_type  stimulation_days  total_fsh_dose trigger_type  \\\n",
      "0  prot_c8a879b2    Antagonist                 9            3598          hCG   \n",
      "1  prot_8f44ccf8          Mild                14            4051          hCG   \n",
      "2  prot_8e0ce0bd          Long                14            4833         Dual   \n",
      "\n",
      "  recommended_protocol  \n",
      "0           Antagonist  \n",
      "1              Agonist  \n",
      "2              Agonist  \n",
      "\n",
      "TABLE: dim_outcome\n",
      "     outcome_id risk_level response_type  suggested_waiting_period_days  \\\n",
      "0  out_1e0526b3   Moderate        Normal                            138   \n",
      "1  out_76cb8ffb       High          Poor                             65   \n",
      "2  out_fd613743       High          Poor                            170   \n",
      "\n",
      "         failure_reason  \n",
      "0               Unknown  \n",
      "1               Unknown  \n",
      "2  Implantation Failure  \n",
      "\n",
      "TABLE: dim_embryo\n",
      "      embryo_id fresh_et_stage grading  class_a_rate\n",
      "0  emb_d3c7cbf1             D3       A           1.0\n",
      "1  emb_3ca809f9             D5       C           0.0\n",
      "2  emb_74c5aa80             D5       C           0.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "conn = sqlite3.connect(DB)\n",
    "\n",
    "# 1️⃣  عرض كل الجداول الموجودة فعليًا:\n",
    "print(\"\\n--- ALL TABLES IN DB ---\")\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(tables)\n",
    "\n",
    "# 2️⃣  عرض عدد الصفوف لكل جدول:\n",
    "print(\"\\n--- ROW COUNTS ---\")\n",
    "for t in tables['name']:\n",
    "    count = pd.read_sql(f\"SELECT COUNT(*) as rows FROM {t};\", conn)\n",
    "    print(f\"{t:<25} → {count['rows'][0]} rows\")\n",
    "\n",
    "# 3️⃣  عرض أول 3 صفوف من كل جدول (لو فيه بيانات):\n",
    "print(\"\\n--- SAMPLE DATA (LIMIT 3) ---\")\n",
    "for t in tables['name']:\n",
    "    try:\n",
    "        sample = pd.read_sql(f\"SELECT * FROM {t} LIMIT 3;\", conn)\n",
    "        print(f\"\\nTABLE: {t}\")\n",
    "        print(sample)\n",
    "    except:\n",
    "        print(f\"\\nTABLE: {t} → Error or no rows\")\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4facd6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Excel saved at: E:\\work\\DEPI\\graduation promax\\data\\warehouse_final\\database_dump.xlsx\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# ================================\n",
    "# 1) PATHS\n",
    "# ================================\n",
    "db_path = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\warehouse_final\\ivf_star_schema.db\"\n",
    "excel_output = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\warehouse_final\\database_dump.xlsx\"\n",
    "\n",
    "# ================================\n",
    "# 2) CONNECT TO DB\n",
    "# ================================\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# ================================\n",
    "# 3) READ TABLE NAMES\n",
    "# ================================\n",
    "tables = pd.read_sql(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'\",\n",
    "    conn\n",
    ")\n",
    "\n",
    "table_list = tables[\"name\"].tolist()\n",
    "\n",
    "# ================================\n",
    "# 4) EXPORT TO EXCEL\n",
    "# ================================\n",
    "with pd.ExcelWriter(excel_output, engine=\"openpyxl\") as writer:\n",
    "    for tbl in table_list:\n",
    "        df = pd.read_sql(f\"SELECT * FROM {tbl}\", conn)\n",
    "        df.to_excel(writer, sheet_name=tbl[:31], index=False)  # Excel sheet name limit\n",
    "\n",
    "# ================================\n",
    "# 5) CLOSE CONNECTION\n",
    "# ================================\n",
    "conn.close()\n",
    "\n",
    "print(\"Done! Excel saved at:\", excel_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ee5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               doctor_recommendation\n",
      "0  Increase gonadotropin dose in next cycle for b...\n",
      "1  Proceed with embryo freezing for future transfer.\n",
      "2  Monitor progesterone closely during luteal phase.\n",
      "3  Consider switching to mild stimulation protoco...\n",
      "4            Good prognosis, continue same protocol.\n",
      "5  Optimize sperm selection for ICSI in next atte...\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DB = r\"E:\\work\\github graduation project local\\Graduation-Project\\graduation project final\\data\\raw\\ivf_database_updated.db\"\n",
    "\n",
    "conn = sqlite3.connect(RAW_DB)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    doctor_recommendation\n",
    "FROM ivf_patients\n",
    "WHERE doctor_recommendation IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1c5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
